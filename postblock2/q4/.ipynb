{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bornsch/IBM-Course/blob/main/postblock2/q4/.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mpch8qowYUzY"
      },
      "source": [
        "# Map Reduce\n",
        "\n",
        "This notebook is performing map reduce in a simplified manner in Python. Distribution of compute to different nodes is not done here; the purpose rather is to explore how to implement a map or reduce function, assuming that the functionality is provided akin to the libraries mentioned in [Dean and Ghemawat](https://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf).\n",
        "\n",
        "\n",
        "This notebook comprises a section defining identity mappers and reducers, along with a `run` method which you may change if necessary. An intermediate sort function is also provided.\n",
        "\n",
        "Implement the `mapper` and `reducer` in the Term Vectors section, and use the run cell as provided.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZSJbq4LYUzc",
        "outputId": "f52be8cc-f2ab-4dd2-8417-1062d50213a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from itertools import groupby\n",
        "from operator import itemgetter\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "%config Completer.use_jedi = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YvK0pYIOYUzf"
      },
      "outputs": [],
      "source": [
        "# Empty MAPPER\n",
        "def mapper(key, value):\n",
        "    \"\"\"\n",
        "    Our user defined mapper function .\n",
        "    : param key :\n",
        "    : param value :\n",
        "    \"\"\"\n",
        "    yield (key, value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8nqXThLnYUzf"
      },
      "outputs": [],
      "source": [
        "# Empty REDUCER\n",
        "\n",
        "def reducer(key , list_value):\n",
        "    \"\"\"\n",
        "    User defined reducer.\n",
        "    : param key :\n",
        "    : param list_value :\n",
        "    \"\"\"\n",
        "    yield (key, list_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wrd1IA-VYUzg",
        "outputId": "abf9c111-cf37-4082-bee2-92fca3704351"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:8: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "<>:8: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "<ipython-input-4-7f9db209101c>:8: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if not (word is '' or word in stopwords.words('english')):\n"
          ]
        }
      ],
      "source": [
        "def cleaner(line):\n",
        "    # lowercase all words and get alphabetical char only and keeping\n",
        "    # apostrophe for time being\n",
        "    words = re.findall(r'[a-z\\']+' , line.lower())\n",
        "    for word in words :\n",
        "        # we will omit apostrophe's assuming users won't type them in a search\n",
        "        word = word.replace(\"'\" , '')\n",
        "        if not (word is '' or word in stopwords.words('english')):\n",
        "            yield word\n",
        "\n",
        "def intermediate_sort(data):\n",
        "    \"\"\"\n",
        "    collect by key\n",
        "    \"\"\"\n",
        "    data = sorted ( data )\n",
        "    return [(k, list(tuple(zip(*g))[1])) for k, g  in groupby(data , itemgetter(0))]\n",
        "\n",
        "def run(sources_dict):\n",
        "    \"\"\"\n",
        "    Since we are focusing on the mapper and reducer functions here we have to\n",
        "    provide the boiler plate code that a MapReduce library typically would . This\n",
        "    function does that in a simple way (we ignore distributing it for now).\n",
        "    : param sources_dict : dictionary where (key,fqfilename), for example ('doc_id','/home/fileX')\n",
        "    \"\"\"\n",
        "    map_result =[]\n",
        "    reduce_result =[]\n",
        "    # open the files and apply map to each of them ( could be done in parallel ,\n",
        "    # but we prefer to keep it simple ) .\n",
        "    for k , v in sources_dict.items():\n",
        "        # do map per source\n",
        "        # this could happen in its own process / worker typically\n",
        "        f = open(v, 'r')\n",
        "        map_result += list(mapper(k, f.read()))\n",
        "        f.close()\n",
        "#         ::alt\n",
        "#          with open(v, 'r') as f:\n",
        "#             for line in f.readlines():\n",
        "#                 map_result += list(mapper(k, line))\n",
        "    # this would be written to disk in the original paradigm,\n",
        "    # but we keep it in memory for ease of use\n",
        "    intermediate_result = intermediate_sort(map_result)\n",
        "    # now that the data has been ' collected ' and grouped by key it can be handed\n",
        "    # to the reducers. They would run over partitions or chunks usually , but we\n",
        "    # will just iterate through the keys we have and call them\n",
        "    for elem in intermediate_result:\n",
        "        reduce_result.append(list(reducer(elem [0], elem [1])))\n",
        "    return map_result, intermediate_result, reduce_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOu9hHx4YUzh",
        "outputId": "cfc4cff3-cae5-43c5-82b3-c14d0c4534f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('D1', ['D1 : the cat sat on the mat\\n'])],\n",
              " [('D2', ['D2 : the dog sat on the log\\n'])]]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# EXAMPLE\n",
        "!mkdir -p input/\n",
        "!echo -e 'D1 : the cat sat on the mat' > input/d1.txt\n",
        "!echo -e 'D2 : the dog sat on the log' > input/d2.txt\n",
        "\n",
        "_, _, res = run({'D1': 'input/d1.txt' , 'D2': 'input/d2.txt'})\n",
        "\n",
        "res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWs5iPsFYUzh"
      },
      "source": [
        "# Term Vector\n",
        "\n",
        "The paper states:\n",
        "\n",
        "> Term-Vector per Host: A term vector summarizes the most important words that occur in a document or a set of documents as a list of 〈word, frequency〉 pairs. The map function emits a 〈hostname, term vector〉 pair for each input document (where the hostname is extracted from the URL of the document). The reduce function is passed all per-document term vectors for a given host. It adds these term vectors together, throwing away infrequent terms, and then emits a final〈hostname, term vector〉 pair.\n",
        "\n",
        "As for\n",
        "\n",
        "> throwing away infrequent terms\n",
        "\n",
        "Write your code in such a way that only terms occurring at least twice are retained.\n",
        "\n",
        "Hint:\n",
        "  * Consider how they use the word 'frequency' elsewhere in the paper.\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BdQ1FyS3YUzi"
      },
      "outputs": [],
      "source": [
        "# your mapper\n",
        "# the map function emits a 〈hostname, term vector〉 pair for each input\n",
        "# document (where the hostname is extracted from the URL of the document)\n",
        "\n",
        "from urllib.parse import urlparse\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def mapper(key, value):\n",
        "    if not key.startswith(('http://', 'https://')):\n",
        "        key = 'http://' + key\n",
        "\n",
        "    url = urlparse(key)\n",
        "    hostname = url.netloc\n",
        "\n",
        "    words = re.findall(r'\\b\\w+\\b', value.lower())\n",
        "    term_vector = Counter(words)\n",
        "\n",
        "    yield (hostname, term_vector)\n",
        "\n",
        "# The reduce function is passed all per-document term vectors for a given host.\n",
        "# It adds these term vectors together, throwing away infrequent terms, and then\n",
        "# emits a final〈hostname, term vector〉 pair.\n",
        "\n",
        "def reducer(key, list_value):\n",
        "    combined_term_vector = Counter()\n",
        "\n",
        "    for term_vector in list_value:\n",
        "        combined_term_vector.update(term_vector)\n",
        "\n",
        "    # raw count word frequency (<= 2 for demonstration)\n",
        "    filtered = {term: count for term, count in combined_term_vector.items() if count >= 2}\n",
        "\n",
        "    yield (key, filtered)\n",
        "\n",
        "# Write example .txt files\n",
        "\n",
        "page1_content = \"\"\"\n",
        "Everything about the destination makes it a paradise for party people.\n",
        "The Thai people’s culture, Bangkok’s infamous party and red light scene to\n",
        "hosting Asia’s largest parties.\n",
        "\"\"\"\n",
        "\n",
        "page2_content = \"\"\"\n",
        "The weather is hot and sticky all year round, the traffic is crazy, yet the people still come.\n",
        "Bangkok now holds the title of the world’s most-visited city.\n",
        "\"\"\"\n",
        "\n",
        "with open('page1.txt', 'w') as file1:\n",
        "        file1.write(page1_content)\n",
        "\n",
        "with open('page2.txt', 'w') as file2:\n",
        "        file2.write(page2_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rqvbpr8mYUzj"
      },
      "outputs": [],
      "source": [
        "x, y, res = run({'www.somesite.com/page/1': 'page1.txt', 'www.somesite.com/page/2': 'page2.txt'})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgFRvUa_qfAu",
        "outputId": "22ed3205-bd9a-48bf-c111-8907ec4293fd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('www.somesite.com',\n",
              "  Counter({'everything': 1,\n",
              "           'about': 1,\n",
              "           'the': 2,\n",
              "           'destination': 1,\n",
              "           'makes': 1,\n",
              "           'it': 1,\n",
              "           'a': 1,\n",
              "           'paradise': 1,\n",
              "           'for': 1,\n",
              "           'party': 2,\n",
              "           'people': 2,\n",
              "           'thai': 1,\n",
              "           's': 3,\n",
              "           'culture': 1,\n",
              "           'bangkok': 1,\n",
              "           'infamous': 1,\n",
              "           'and': 1,\n",
              "           'red': 1,\n",
              "           'light': 1,\n",
              "           'scene': 1,\n",
              "           'to': 1,\n",
              "           'hosting': 1,\n",
              "           'asia': 1,\n",
              "           'largest': 1,\n",
              "           'parties': 1})),\n",
              " ('www.somesite.com',\n",
              "  Counter({'the': 5,\n",
              "           'weather': 1,\n",
              "           'is': 2,\n",
              "           'hot': 1,\n",
              "           'and': 1,\n",
              "           'sticky': 1,\n",
              "           'all': 1,\n",
              "           'year': 1,\n",
              "           'round': 1,\n",
              "           'traffic': 1,\n",
              "           'crazy': 1,\n",
              "           'yet': 1,\n",
              "           'people': 1,\n",
              "           'still': 1,\n",
              "           'come': 1,\n",
              "           'bangkok': 1,\n",
              "           'now': 1,\n",
              "           'holds': 1,\n",
              "           'title': 1,\n",
              "           'of': 1,\n",
              "           'world': 1,\n",
              "           's': 1,\n",
              "           'most': 1,\n",
              "           'visited': 1,\n",
              "           'city': 1}))]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSwGG99LqhPu",
        "outputId": "67fb290d-8919-4b6a-a3b4-82047f697113"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('www.somesite.com',\n",
              "  [Counter({'everything': 1,\n",
              "            'about': 1,\n",
              "            'the': 2,\n",
              "            'destination': 1,\n",
              "            'makes': 1,\n",
              "            'it': 1,\n",
              "            'a': 1,\n",
              "            'paradise': 1,\n",
              "            'for': 1,\n",
              "            'party': 2,\n",
              "            'people': 2,\n",
              "            'thai': 1,\n",
              "            's': 3,\n",
              "            'culture': 1,\n",
              "            'bangkok': 1,\n",
              "            'infamous': 1,\n",
              "            'and': 1,\n",
              "            'red': 1,\n",
              "            'light': 1,\n",
              "            'scene': 1,\n",
              "            'to': 1,\n",
              "            'hosting': 1,\n",
              "            'asia': 1,\n",
              "            'largest': 1,\n",
              "            'parties': 1}),\n",
              "   Counter({'the': 5,\n",
              "            'weather': 1,\n",
              "            'is': 2,\n",
              "            'hot': 1,\n",
              "            'and': 1,\n",
              "            'sticky': 1,\n",
              "            'all': 1,\n",
              "            'year': 1,\n",
              "            'round': 1,\n",
              "            'traffic': 1,\n",
              "            'crazy': 1,\n",
              "            'yet': 1,\n",
              "            'people': 1,\n",
              "            'still': 1,\n",
              "            'come': 1,\n",
              "            'bangkok': 1,\n",
              "            'now': 1,\n",
              "            'holds': 1,\n",
              "            'title': 1,\n",
              "            'of': 1,\n",
              "            'world': 1,\n",
              "            's': 1,\n",
              "            'most': 1,\n",
              "            'visited': 1,\n",
              "            'city': 1})])]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yV-igUDwqgoy",
        "outputId": "61e8a8f3-7dd5-4f83-de0f-2a2c1a6387f5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('www.somesite.com',\n",
              "   {'the': 7,\n",
              "    'party': 2,\n",
              "    'people': 3,\n",
              "    's': 4,\n",
              "    'bangkok': 2,\n",
              "    'and': 2,\n",
              "    'is': 2})]]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def m(key, value):\n",
        "#     if not key.startswith(('http://', 'https://')):\n",
        "#         key = 'http://' + key\n",
        "\n",
        "#     url = urlparse(key)\n",
        "#     hostname = url.netloc\n",
        "\n",
        "#     words = re.findall(r'\\b\\w+\\b', value.lower())\n",
        "#     term_vector = Counter(words)\n",
        "\n",
        "#     return [(hostname, term_vector)]\n",
        "\n",
        "# a = m('www.somesite.com/page/1', page1_content)\n",
        "# b = m('www.somesite.com/page/2', page2_content)\n",
        "\n",
        "# print(a)\n",
        "# print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Xtf1quOdYM-",
        "outputId": "f90dfbb8-7600-4f1c-8c69-479f5de2dbce"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('www.somesite.com', Counter({'s': 3, 'the': 2, 'party': 2, 'people': 2, 'everything': 1, 'about': 1, 'destination': 1, 'makes': 1, 'it': 1, 'a': 1, 'paradise': 1, 'for': 1, 'thai': 1, 'culture': 1, 'bangkok': 1, 'infamous': 1, 'and': 1, 'red': 1, 'light': 1, 'scene': 1, 'to': 1, 'hosting': 1, 'asia': 1, 'largest': 1, 'parties': 1}))]\n",
            "[('www.somesite.com', Counter({'the': 5, 'is': 2, 'weather': 1, 'hot': 1, 'and': 1, 'sticky': 1, 'all': 1, 'year': 1, 'round': 1, 'traffic': 1, 'crazy': 1, 'yet': 1, 'people': 1, 'still': 1, 'come': 1, 'bangkok': 1, 'now': 1, 'holds': 1, 'title': 1, 'of': 1, 'world': 1, 's': 1, 'most': 1, 'visited': 1, 'city': 1}))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def r(key, list_value):\n",
        "#     combined_term_vector = Counter()\n",
        "\n",
        "#     for term_vector in list_value:\n",
        "#         combined_term_vector.update(term_vector)\n",
        "\n",
        "#     filtered = {term: count for term, count in combined_term_vector.items() if count >= 2}\n",
        "\n",
        "#     return key, filtered\n",
        "\n",
        "# c = r(a[0][0], [a[0][1], b[0][1]])\n",
        "\n",
        "# print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIBKjN_vdmaK",
        "outputId": "271f48aa-70b8-434e-db1d-9e4d7611acaa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('www.somesite.com', {'the': 7, 'party': 2, 'people': 3, 's': 4, 'bangkok': 2, 'and': 2, 'is': 2})\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "bdt-a3",
      "language": "python",
      "name": "bdt-a3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}